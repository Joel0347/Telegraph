\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{multirow}
\usepackage{listings}
\usepackage{xcolor}

% Definir colores
\definecolor{codegreen}{rgb}{0.1,0.4,0.1}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

% Definir lenguaje JSON
\lstdefinelanguage{json}{
    basicstyle=\ttfamily\footnotesize,
    numbers=left,
    numberstyle=\tiny\color{codegray},
    backgroundcolor=\color{backcolour},
    showspaces=false,
    showstringspaces=false,
    breaklines=true,
    frame=single,
    commentstyle=\color{codegreen},
    keywordstyle=\color{blue},
    stringstyle=\color{codepurple},
    morecomment=[s][\color{codegreen}]{/*}{*/},
    morestring=[b]",
    morestring=[d]"
}
\addto\captionsspanish{
  \renewcommand{\listtablename}{Índice de tablas}
  \renewcommand{\tablename}{Tabla}
}
\geometry{margin=1in}
\title{Informe de Diseño del Proyecto}
\author{Claudia Hernández Pérez \and Joel Aparicio Tamayo}
\date{Noviembre, 2025}

\begin{document}
\maketitle
\begin{abstract}
    \textit{Telegraph} es una aplicación de mensajería distribuida con una arquitectura peer-to-peer en
la que cualquier cliente puede recibir y mandar mensajes con la garantía de que solo lo podrán ver los 
involucrados en la conversación. Existen dos entidades fundamentales: cliente y gestor de entidades. 
Los clientes son el sistema en sí y la comunicación entre estos es la piedra angular de la tarea, mientras que 
los gestores de identidades son los encargados de manejar la información de los usuarios.
\end{abstract}

\section{Arquitectura}

Los sistemas distribuidos modernos han evolucionado a través de diversos modelos arquitectónicos que buscan optimizar la
escalabilidad, tolerancia a fallos y eficiencia en la comunicación. Entre estos modelos, las arquitecturas \textit{peer-to-peer}
(P2P) han demostrado ser particularmente efectivas para aplicaciones que requieren descentralización y colaboración directa entre nodos.

Las arquitecturas P2P se caracterizan por la ausencia de roles fijos entre clientes y servidores, donde todos los nodos participan
activamente tanto en la provisión como en el consumo de servicios. Existen principalmente dos variantes: los sistemas \textbf{P2P estructurados},
que organizan los nodos en topologías deterministas como anillos o DHTs para permitir búsquedas eficientes; y los sistemas \textbf{P2P no estructurados},
donde las conexiones entre nodos se establecen de forma ad-hoc (no siguen un plan preestablecido).

\subsection{Organización del sistema distribuido}
\textit{Telegraph} basa su funcionamiento en una arquitectura \textit{peer-to-peer} no estructurada con un funcionamiento
inspirado en \textit{BitTorrent}: los clientes, para enviar mensajes, consultan a los gestores de identidades para 
obtener la \texttt{IP} del destinatario y establecer comunicación directa con él, lo cual es un comportamiento similar
a la solicitud de \texttt{peers} a los \texttt{trackers}, para intercambiar \texttt{chunks} entre ellos.

\subsection{Roles existentes en el sistema}
En el sistema existen dos roles principales: clientes (\textit{clients}) y gestores de identidades (\textit{identity managers}).:

\begin{enumerate}
    \item \textbf{gestor de identidades}: es el responsable de gestionar toda la información de las cuentas, tal como:
        \begin{itemize}
            \item Nombre de usuario
            \item Contraseña encriptada
            \item Dirección \texttt{IP} y puerto
            \item Estado de conexión (en línea ó desconectado)
            \item Última vez visto en línea
        \end{itemize}
    \item \textbf{clientes}: pueden comunicarse entre sí directamente sin un servidor centralizado que almacene mensajes temporalmente. Cada cliente puede realizar las siguientes acciones:

\begin{itemize}
    \item Enviar mensajes
    \item Recibir mensajes
    \item Notificar que un mensaje ha sido leído
    \item Reintentar el envío de mensajes pendientes a usuarios fuera de línea
\end{itemize}
\end{enumerate}

\subsection{Distribución de servicios en ambas redes de Docker}

La implementación del sistema distribuido se despliega utilizando \textit{Docker Swarm} con una red \texttt{overlay attachable} que permite la comunicación transparente entre contenedores ejecutándose en diferentes hosts físicos. Esta configuración replica un entorno de producción real donde los servicios están distribuidos geográficamente.

\begin{itemize}
    \item \textbf{Balanceo de Clientes}: Los clientes \textbf{P2P} pueden desplegarse en ambos hosts (tantos como se deseen), simulando usuarios en diferentes ubicaciones de red. Lo que se recomienda es balancear entre ambos hosts físicos para sobrecargar lo menos posible cada uno.
    
    \item \textbf{Distribución de Gestores}: Inicialmente el sistema contará con $4k - 2$ réplicas de gestores (siendo $k$ la tolerancia a fallas esperada), donde cada host contará con $2k-1$ gestores. De esta forma se garantiza que si se pierde la conexión entre ambos hosts físicos, en cada red independiente se logre una tolerancia a fallas $k-1$. Esta desición puede estra sujeta a cambios futuros.
    
    \item \textbf{Descubrimiento de Servicios}: \textit{Docker Swarm} proporciona un \textbf{DNS} interno que permite a los contenedores descubrir automáticamente los servicios desplegados en la red \texttt{overlay}. Además, se cuenta con una alternativa ante posibles fallos del \textbf{DNS} que se explicará en otra sección más adelante.
\end{itemize}


\section{Procesos}

Los sistemas distribuidos están constituidos por procesos que representan las unidades fundamentales de ejecución, responsables de llevar a cabo las diversas tareas y servicios que componen el sistema. Estos procesos, distribuidos en múltiples nodos de red, cooperan y se comunican para ofrecer funcionalidades integradas y transparentes al usuario final. La correcta organización y coordinación entre procesos determina en gran medida la escalabilidad, eficiencia y confiabilidad del sistema distribuido. En el contexto de \textit{Telegraph}, el sistema se estructura alrededor de dos tipos principales de procesos: los procesos del cliente y los del gestor.

\subsection{Tipos de procesos dentro del sistema}

El sistema implementa una arquitectura de procesos especializados que se dividen en dos categorías principales:

\begin{itemize}
    \item \textbf{Procesos del gestor}:
    \begin{itemize}
        \item \textbf{Servidor \textit{Flask}}: Proceso que expone \texttt{API REST} para autenticación, registro, resolución de direcciones \texttt{IP}, entre otras solicitudes.
        \item \textbf{\textit{Worker} de verificación}: Proceso periódico con APScheduler que monitorea los usuarios inactivos del sistema y actualiza su estado a \textit{offline}.
        \item \textbf{Servidor \texttt{UDP}}: Proceso que mantiene un \texttt{socket UDP} abierto para descubrimiento alternativo de gestores.
    \end{itemize}
    
    \item \textbf{Procesos del cliente}:
    \begin{itemize}
        \item \textbf{Interfaz Streamlit}: Proceso que renderiza la interfaz gráfica y gestiona la interacción del usuario.
        \item \textbf{Servidor \textit{Flask}}: Proceso que expone \texttt{API REST} para comunicación entre clientes.
        \item \textbf{\textit{Worker} para tareas pendientes}: Tareas programadas con APScheduler para gestionar mensajes o actualizaciones de estado pendientes.
        \item \textbf{Servicio de mensajería}: Componente que establece conexiones directas con otros clientes para envío de mensajes.
        \item \textbf{Servicio para comunicación con gestores}: Componente encargado del descubrimiento inicial de gestores, así como de todas las solicitudes que les envían los clientes.
    \end{itemize}
\end{itemize}

\subsection{Organización o agrupación de los procesos en el sistema}

Los procesos del sistema se agrupan en las dos categorías ya conocidas. Cada una posee un proceso principal y el resto ejecutan tareas en segundo plano:

\begin{itemize}
    \item \textbf{Organización de procesos del gestor}:
    \begin{itemize}
        \item \textbf{Proceso principal}: Servidor \textit{Flask}
        \item \textbf{Procesos independientes en segundo plano}: \textit{Worker} de verificación y servidor \texttt{UDP}.
    \end{itemize}

    \item \textbf{Organización de procesos del cliente}:
    \begin{itemize}
        \item \textbf{Proceso principal}: Interfaz de \textit{Streamlit}. Cada vez que se renderiza, se emplea el componente de comunicación con gestores para enviar señales de vida y obtener el listado de clientes activos. Con las interacciones del usuario se utiliza, además, el servicio de mensajería para comunicarse.
        \item \textbf{Procesos independientes en segundo plano}: \textit{Worker} para tareas pendientes y servidor \textit{Flask}. Aunque este último no se comunica directamente con el servicio de mensajería ni con el \textit{Worker} dentro del propio cliente, sí son componentes relacionados, ya que los mensajes llegan de emisor a receptor por solicitudes \texttt{HTTP} que recaen sobre dicho servidor. Igualmente, los mensajes y notificaciones de lectura pendientes que se reintentan llegan a los \textit{end-points} de \textit{Flask} en el receptor.
    \end{itemize}
\end{itemize}

\subsection{Tipo de patrón de diseño con respecto al desempeño}

El sistema implementa \textbf{concurrencia basada en hilos} bajo el modelo \textbf{Many-to-One}:

\begin{itemize}
    \item \textbf{Hilos especializados}: Diferentes componentes ejecutan en hilos separados dentro del mismo proceso:
        \begin{itemize}
            \item \textbf{cliente}: El proceso principal es el que ejecuta la interfaz gráfica de \textit{Streamlit}. De él se desprenden dos hilos: uno para el \textit{APScheduler} encargado de las tareas pendientes y otro para el servidor de \textit{Flask}. El resto de tareas se ejecutan en el proceso principal.
            \item \textbf{gestor}: El proceso principal es el que ejecuta el servidor de \textit{Flask}. De él se desprenden dos hilos: uno para el \textit{APScheduler} encargado de detectar usuarios inactivos y otro para el servidor \texttt{UDP}.
        \end{itemize}
    
    \item \textbf{Hilo por solicitud}: Los servidores \textit{Flask} con \texttt{threaded=True} implementan este patrón para manejar múltiples solicitudes \texttt{HTTP} concurrentemente.
\end{itemize}


\section{Comunicación}

La comunicación es uno de los pilares fundamentales en los sistemas distribuidos, permitiendo la interacción y coordinación entre componentes dispersos en diferentes nodos de red. En este tipo de sistemas, los procesos deben intercambiar información de manera confiable y eficiente, a pesar de las limitaciones inherentes de la red como latencia, pérdida de paquetes y fallos parciales. La elección adecuada de los mecanismos de comunicación determina en gran medida el desempeño, escalabilidad y confiabilidad del sistema como un todo.

\subsection{Tipos de comunicación}
\textit{Telegraph} utiliza dos tipos de comunicación fundamentales:

\begin{itemize}
    \item \textbf{\texttt{API REST}}: Utilizado como mecanismo principal para la comunicación. Permite ejecutar acciones sobre la base de datos a partir de solicitudes.
    \item \textbf{\texttt{Sockets UDP}}: Implementado como mecanismo de descubrimiento de servicios alternativo.
\end{itemize}

\subsection{Comunicación cliente-servidor}
La comunicación cliente-servidor se basa en el patrón \textbf{solicitud-respuesta} (\textit{request-reply}) donde el cliente envía un mensaje de solicitud al servidor (gestor u otro cliente), que recibe y procesa la solicitud, devolviendo finalmente un mensaje de respuesta. En \hyperref[tab:tipos-comunicacion]{Tabla 1} se pueden apreciar ejemplos de la implementación.

\begin{table}[h]
\centering
\label{tab:tipos-comunicacion}
\begin{tabular}{|p{3cm}|p{5.5cm}|p{5.5cm}|}
\hline
\textbf{Tipo} & \textbf{Solicitud del Cliente} & \textbf{Respuesta del Servidor} \\
\hline
\multirow{14}{*}{\textbf{API REST}} 
& \url{/login}, method=[POST], content=\{username, password, ip, port\} & \texttt{CG}

\{"message": "Login exitoso", "status": 200\} \\
\cline{2-3}

& \url{/users/<username>}, method=[GET] & \texttt{CG}

\{"message": \{...\}, "status": 200\} \\
\cline{2-3}

& \url{/heartbeat}, method=[POST], 

content=\{username\} & \texttt{CG} 

\{"message": "heartbeat recibido", "status": 200\} \\
\cline{2-3}

& \url{/users/reconnect/<ip>/<username>}, method=[PUT] & \texttt{CG}

\{"message": `IP actualizada exitosamente', "status": 200\} \\
\cline{2-3}

& \url{/notify\_read}, method=[POST], 

content=\{from, to\} & \texttt{CC}

\{"marked": count\}, 200 \\
\cline{2-3}

& POST \url{/receive\_message}, method=[POST],

content=\{from, to, text\} & \texttt{CC}

\{"status": `ok'\}, 200 \\
\cline{2-3}
\hline
\multirow{1}{*}{\textbf{Socket UDP}}
& \{`action': `discover'\} & \{`status': `active'\} \\
\hline
\end{tabular}

\caption{Comunicación cliente-servidor. \texttt{CC} denota la comunicación entre clientes (uno actuando como servidor) y \texttt{CG} la comunicación del cliente con el gestor}
\end{table}

\subsection{Comunicación servidor-servidor}
\dots

\subsection{Comunicación entre procesos}
En el sistema, cada nodo (gestor o cliente) ejecuta un proceso principal y varios procesos independientes en segundo plano. Como todos los componentes se ejecutan como hilos dentro del mismo espacio de memoria, la interacción entre ellos se realiza mediante acceso directo a objetos compartidos, por lo que sí se maneja coordinación, sin embargo, 
\textbf{no existe comunicación entre procesos en el mismo nodo},
\section{Coordinación}
\dots
\section{Nombrado y Localización}


La identificación y localización de recursos constituye uno de los desafíos fundamentales en el diseño de sistemas distribuidos. En un entorno donde los componentes están físicamente dispersos a través de múltiples nodos de red, es esencial contar con mecanismos que permitan a los procesos encontrar y acceder de manera eficiente a los servicios y datos que necesitan para operar. 

\subsection{Identificación de los datos y servicios}

El sistema almacena dos tipos de información:
\begin{itemize}
    \item \textbf{Usuarios}: Se identifican por el campo \texttt{username} único para cada usuario.
        \begin{lstlisting}[language=json, breaklines=False, basicstyle=\scriptsize \ttfamily]
{
  "username": "alice",
  "password": "$2b$12$LQv3c1yqBWVHxkd0g8f7QuYKThbMvOoiuTM.ZlbzOnY9qU8pMq.LK",
  "ip": "192.168.1.150",
  "port": 8000,
  "status": "online", /* puede ser "offline" tambien */
  "last_seen": "2025-11-15T14:30:25.123456Z"
}
        \end{lstlisting}
    \item \textbf{Mensajes}: Se identifican por la llave \texttt{(from, to, timestamp)} única por mensaje.
        \begin{lstlisting}[language=json,basicstyle=\ttfamily\scriptsize, breaklines=false]
{
  "from": "alice",
  "to": "bob",
  "text": "Aprobamos Distribuidos",
  "timestamp": "2025-11-15T16:45:30.789123Z",
  "read": false,
  "status": "ok" /* puede ser "pending" tambien */
}
\end{lstlisting}

\end{itemize}

Además de datos, es posible identificar nodos y servicios:
\begin{itemize}
    \item \textbf{Gestores}: Todos poseen el mismo alias en la red: \texttt{identity-manager}; aunque cada uno tiene su propia dirección \texttt{IP}.
    \item \textbf{Clientes}: Guardan su dirección \texttt{IP} en los datos del usuario conectado desde ese nodo.
    \item \textbf{Servicios \texttt{REST}}: Se identifican por una \textit{url}: \url{Node_IP:Puerto/endpoint}. Cada funcionalidad se expone mediante \textit{endpoints} específicos como \texttt{/login}, \texttt{/register}, \texttt{/peers}, \texttt{/receive\_message}, etc.
\end{itemize}

\subsection{Ubicación de los datos y servicios}

Los datos del sistema se almacenan en archivos \texttt{.json} distribuidos de la siguiente manera:

\begin{itemize}
    \item \textbf{Datos de Usuarios}: Almacenados localmente en cada gestor.
    \item \textbf{Mensajes}: Almacenados localmente en los clientes que intervienen en la conversación.
\end{itemize}

Los servicios \texttt{REST} se distribuyen de la siguiente forma:
\begin{itemize}
    \item \textbf{Servicios de Gestores}: Desplegados con puerto fijo 8000.
    \item \textbf{Servicios de Clientes}: Desplegados en un puerto dinámico, por defecto: 8000.
\end{itemize}

\subsection{Localización de los datos y servicios}

Los nodos del sistema implementan dos mecanismos de descubrimiento de gestores, evitando depender de un único servicio que, eventualmente, podría fallar.

\begin{itemize}
    \item \textbf{Descubrimiento Primario}: Todos los gestores tienen el mismo alias, que se utiliza para solicitar al \textbf{DNS} de \textit{Docker} todas las direcciones \texttt{IP} registradas con ese nombre.
    \item \textbf{Descubrimiento Secundario}: Como mecanismo de \textit{fallback}, los clientes escanean un rango de \texttt{IP} predefinido cuando el \textbf{DNS} de \textit{Docker} no está disponible. Luego, envían a cada dirección un mensaje vía \texttt{socket} al puerto \texttt{UDP} en el que se encuentren escuhando los gestores, por defecto: 5353.
\end{itemize}

Los clientes entre sí no necesitan descubrirse unos a otros. Por la arquitectura propuesta, los clientes consultan a los gestores mediante \texttt{GET /users/<username>} para obtener la dirección \texttt{IP} y el puerto del servicio \texttt{REST} de cualquier otro. En caso de que los clientes cambien de dirección \texttt{IP} por alguna desconexión y reconexión de la red, notifican cambios de ubicación mediante \texttt{PUT /users/reconnect/<ip>/<username>} en cuanto se activen nuevamente.

\section{Consistencia y replicación}
La implementación actual no incorpora replicación distribuida ni un anillo Chord. En su lugar se aplica una persistencia local en cada cliente (archivos JSON) y un registro centralizado de usuarios en el identity manager (fichero JSON \path{/data/users.json}).

Consecuencia: no hay tolerancia a particiones en lo que respecta al registro de usuarios; si el manager que contiene el fichero de usuarios deja de estar disponible, los clientes solo pueden actuar con la información cacheada localmente o hasta que descubran otro manager.

\section{Tolerancia a fallos}
Medidas actuales:
- Descubrimiento múltiple: \texttt{ApiHandlerService} intenta localizar managers vía DNS (resolviendo \texttt{identity-manager}) y, si falla, hace broadcast sobre la red overlay para localizar managers activos; mantiene una lista \texttt{api\_urls} y reintenta peticiones a diferentes managers.
- Reintentos y marcadores locales: \texttt{MessageService} marca mensajes como \texttt{pending} si no puede contactar al receptor, y reintenta su envío periódicamente desde las tareas en background.
- Detección de inactividad: el identity manager marca usuarios como offline si no reciben heartbeats y fuerza desconexiones.

Limitaciones:
- No existe replicación de la base de datos de usuarios ni de los mensajes a otros gestores; la tolerancia a fallos está limitada a la disponibilidad de los ficheros JSON del manager y de los propios clientes.

\section{Seguridad}
\subsection{Autenticación y contraseñas}
Las contraseñas de los usuarios se hashean con bcrypt (\texttt{AuthService.hash\_password}) antes de almacenarlas en el repositorio de usuarios (\texttt{UserRepository} guarda datos en JSON en \path{/data/users.json}). La verificación se realiza con \texttt{checkpw}.

\subsection{Canales y cifrado}
En la versión actual no hay cifrado de transporte (no hay TLS configurado en las peticiones HTTP internas). Esto es una área prioritaria de mejora: se recomienda habilitar HTTPS entre managers y clientes y/o establecer túneles VPN / mTLS en despliegues reales.

\subsection{Consideraciones adicionales}
- Validación básica de payloads en endpoints Flask.
- No hay control de acceso granular ni lista blanca de managers; cualquiera que responda al discovery UDP puede ser usado por clientes si le han descubierto.

\section{Conclusiones y trabajo futuro}
La implementación actual es una prueba de concepto funcional que cubre:
- Registro, login y localización de usuarios mediante un \textit{identity manager} ligero.
- Intercambio directo de mensajes entre clientes mediante HTTP y persistencia local de mensajes.
- Mecanismos básicos de disponibilidad (heartbeat, detección de inactividad, reintentos de envío).

Mejoras recomendadas:
- Implementar replicación y tolerancia a fallos entre gestores (por ejemplo, un anillo Chord o replicación maestro-esclavo para \path{users.json}).
- Asegurar canales con TLS/mTLS y proteger el UDP discovery.
- Añadir pruebas automáticas y scripts de despliegue reproducible.

\newpage
\section*{Apéndice: Referencias a código}
Se listan los ficheros más relevantes y su propósito:
- \path{src/client/app/main.py}: UI Streamlit y arranque de servicios.
- \path{src/client/app/server.py}: servidor Flask del cliente (endpoints para recibir mensajes y recibos).
- \path{src/client/app/background_tasks.py}: loop de sincronización y reintentos.
- \path{src/client/app/services/}: lógica de negocio cliente (API handler, client info, message service).
- \path{src/client/app/repositories/}: persistencia local (mensajes, usuario local).
- \path{src/identity-manager/app/api.py}: server REST del manager.
- \path{src/identity-manager/app/udp_discovery.py}: discovery por UDP.
- \path{src/identity-manager/app/services/auth_service.py}: autenticación y gestión de usuarios.

\end{document}